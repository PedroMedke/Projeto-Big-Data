# Prova PrÃ¡tica de CiÃªncia de Dados e Big Data

SoluÃ§Ã£o completa de pipeline de dados com coleta, processamento, armazenamento e visualizaÃ§Ã£o de insights.

## Integrantes 

Olavo Guilherme dos Santos Tomaz  - 1624543
VinÃ­cius Caires De Souza          - 6324613
Luis Gustavo silveira pinto       - 6324670
Pedro Kommers Medke               - 6324623

## ðŸ“‹ Estrutura do Projeto

```
â”œâ”€â”€ docs/                 # DocumentaÃ§Ã£o completa
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingestao/        # Scripts de coleta de dados
â”‚   â”œâ”€â”€ processamento/    # TransformaÃ§Ãµes e processamento
â”‚   â”œâ”€â”€ api/             # API para servir dados
â”‚   â””â”€â”€ dashboards/      # Dashboards e visualizaÃ§Ãµes
â”œâ”€â”€ infrastructure/      # Docker, configs de infraestrutura
â”œâ”€â”€ config/             # Arquivos de configuraÃ§Ã£o
â”œâ”€â”€ data/               # Camadas de armazenamento
â”‚   â”œâ”€â”€ raw/           # Dados brutos
â”‚   â”œâ”€â”€ bronze/        # Dados validados
â”‚   â”œâ”€â”€ silver/        # Dados transformados
â”‚   â””â”€â”€ gold/          # Dados finais para anÃ¡lise
â””â”€â”€ tests/             # Testes unitÃ¡rios
```

### PrÃ©-requisitos
- Python 3.9+
- Docker & Docker Compose
- Git

## ------------------- Inicio Rapido -------------------------------------

PrÃ©-requisitos
Python 3.9+
Docker & Docker Compose
Git
InstalaÃ§Ã£o e ExecuÃ§Ã£o
Clone o repositÃ³rio:
git clone <seu-repo>
cd projeto-bigdata
Configure o ambiente:
python -m venv venv
venv\Scripts\activate  # Windows
source venv/bin/activate  # Linux/Mac
pip install -r requirements.txt
Configure as variÃ¡veis de ambiente:
copy .env.example .env
# Edite .env com suas configuraÃ§Ãµes
Inicie a infraestrutura com Docker:
docker-compose -f infrastructure/docker-compose.yml up -d
Execute o pipeline:
python src/ingestao/main.py
python src/processamento/main.py
Acesse os dashboards:
Metabase: http://localhost:3000
API: http://localhost:5000


##  DocumentaÃ§Ã£o

Consulte a pasta `docs/` para:
- `01_visao_geral.md` - Problema, objetivos e escopo
- `02_arquitetura.md` - Componentes e fluxo de dados
- `03_tecnologias.md` - Stack tecnolÃ³gico
- `04_dados.md` - Origem, formato e dicionÃ¡rio
- `05_decisoes_tecnicas.md` - Trade-offs e alternativas

##  Pipeline de Dados
[Origem] â†’ [IngestÃ£o] â†’ [ValidaÃ§Ã£o] â†’ [Processamento] 
    â†“          â†“             â†“              â†“
  Dados      Raw         Bronze          Silver
   Brutos                                   â†“
                                         [Gold]
                                           â†“
                                    [Dashboards/API]


##  Ferramentas Principais

- **Coleta**: Python requests + Airflow (batch)
- **Processamento**: Apache Spark (PySpark)
- **Armazenamento**: MinIO (S3-compatible)
- **AnÃ¡lise**: Pandas, SQL
- **VisualizaÃ§Ã£o**: Metabase
- **Infraestrutura**: Docker Compose

##  ConfiguraÃ§Ã£o de DependÃªncias

Veja `docs/06_dependencias.md` para versÃµes completas.

##  Testes

```bash
pytest tests/ -v
pytest tests/ --cov=src  # Com cobertura
```

##  Logs e Monitoramento

Logs estÃ£o em `logs/` com rotaÃ§Ã£o automÃ¡tica.


