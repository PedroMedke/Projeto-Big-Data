# Prova PrÃ¡tica de CiÃªncia de Dados e Big Data

SoluÃ§Ã£o completa de pipeline de dados com coleta, processamento, armazenamento e visualizaÃ§Ã£o de insights.

## ğŸ“‹ Estrutura do Projeto

```
â”œâ”€â”€ docs/                 # DocumentaÃ§Ã£o completa
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingestao/        # Scripts de coleta de dados
â”‚   â”œâ”€â”€ processamento/    # TransformaÃ§Ãµes e processamento
â”‚   â”œâ”€â”€ api/             # API para servir dados
â”‚   â””â”€â”€ dashboards/      # Dashboards e visualizaÃ§Ãµes
â”œâ”€â”€ infrastructure/      # Docker, configs de infraestrutura
â”œâ”€â”€ config/             # Arquivos de configuraÃ§Ã£o
â”œâ”€â”€ data/               # Camadas de armazenamento
â”‚   â”œâ”€â”€ raw/           # Dados brutos
â”‚   â”œâ”€â”€ bronze/        # Dados validados
â”‚   â”œâ”€â”€ silver/        # Dados transformados
â”‚   â””â”€â”€ gold/          # Dados finais para anÃ¡lise
â””â”€â”€ tests/             # Testes unitÃ¡rios
```

## ğŸš€ Quick Start

### PrÃ©-requisitos
- Python 3.9+
- Docker & Docker Compose
- Git

### InstalaÃ§Ã£o e ExecuÃ§Ã£o

1. **Clone o repositÃ³rio:**
```bash
git clone <seu-repo>
cd projeto-bigdata
```

2. **Configure o ambiente:**
```bash
python -m venv venv
venv\Scripts\activate  # Windows
source venv/bin/activate  # Linux/Mac
pip install -r requirements.txt
```

3. **Configure as variÃ¡veis de ambiente:**
```bash
copy .env.example .env
# Edite .env com suas configuraÃ§Ãµes
```

4. **Inicie a infraestrutura com Docker:**
```bash
docker-compose -f infrastructure/docker-compose.yml up -d
```

5. **Execute o pipeline:**
```bash
python src/ingestao/main.py
python src/processamento/main.py
```

6. **Acesse os dashboards:**
- Metabase: http://localhost:3000
- API: http://localhost:5000

## ğŸ“š DocumentaÃ§Ã£o

Consulte a pasta `docs/` para:
- `01_visao_geral.md` - Problema, objetivos e escopo
- `02_arquitetura.md` - Componentes e fluxo de dados
- `03_tecnologias.md` - Stack tecnolÃ³gico
- `04_dados.md` - Origem, formato e dicionÃ¡rio
- `05_decisoes_tecnicas.md` - Trade-offs e alternativas

## ğŸ‘¥ Responsabilidades

| Integrante | Responsabilidade |
|-----------|-----------------|
| [Nome] | IngestÃ£o e coleta de dados |
| [Nome] | Processamento e transformaÃ§Ã£o |
| [Nome] | Armazenamento e qualidade |
| [Nome] | API e visualizaÃ§Ãµes |
| [Nome] | Infraestrutura e DevOps |

## ğŸ“Š Pipeline de Dados

```
[Origem] â†’ [IngestÃ£o] â†’ [ValidaÃ§Ã£o] â†’ [Processamento] 
    â†“          â†“             â†“              â†“
  Dados      Raw         Bronze          Silver
   Brutos                                   â†“
                                         [Gold]
                                           â†“
                                    [Dashboards/API]
```

## ğŸ› ï¸ Ferramentas Principais

- **Coleta**: Python requests + Airflow (batch)
- **Processamento**: Apache Spark (PySpark)
- **Armazenamento**: MinIO (S3-compatible)
- **AnÃ¡lise**: Pandas, SQL
- **VisualizaÃ§Ã£o**: Metabase
- **Infraestrutura**: Docker Compose

## âš™ï¸ ConfiguraÃ§Ã£o de DependÃªncias

Veja `docs/06_dependencias.md` para versÃµes completas.

## ğŸ§ª Testes

```bash
pytest tests/ -v
pytest tests/ --cov=src  # Com cobertura
```

## ğŸ“ Logs e Monitoramento

Logs estÃ£o em `logs/` com rotaÃ§Ã£o automÃ¡tica.

## âš ï¸ LimitaÃ§Ãµes e Pontos de Falha

Veja `docs/07_limitacoes.md` para anÃ¡lise detalhada.

## ğŸ“„ LicenÃ§a

MIT

---

**Ãšltima atualizaÃ§Ã£o**: 8 de dezembro de 2025
